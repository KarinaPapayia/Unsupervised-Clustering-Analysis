{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from tensorboardX import SummaryWriter\n",
    "import uuid\n",
    "\n",
    "from lib.DEC import DEC\n",
    "from lib.model import train, predict\n",
    "from lib.sdae import StackedDenoisingAutoEncoder\n",
    "import lib.model_ae as ae\n",
    "from lib.utils import cluster_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedMNIST(Dataset):\n",
    "    def __init__(self, train, cuda, testing_mode=False):\n",
    "        img_transform = transforms.Compose([\n",
    "            transforms.Lambda(self._transformation)\n",
    "        ])\n",
    "        self.ds = MNIST(\n",
    "            './data',\n",
    "            download = True,\n",
    "            train = train,\n",
    "            transform = img_transform\n",
    "        )\n",
    "        self.cuda = cuda\n",
    "        self.testing_mode = testing_mode\n",
    "        self._cache = dict()\n",
    "\n",
    "    @staticmethod\n",
    "    def _transformation(img):\n",
    "        return torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes())).float() * 0.02\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        if index not in self._cache:\n",
    "            self._cache[index] = list(self.ds[index])\n",
    "            if self.cuda:\n",
    "                self._cache[index][0] = self._cache[index][0].cuda(non_blocking=True)\n",
    "                self._cache[index][1] = torch(self._cache[index][1]).cuda(non_blocking=True)\n",
    "        return self._cache[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return 128 if self.testing_mode else len(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    cuda,\n",
    "    batch_size,\n",
    "    pretrain_epochs,\n",
    "    finetune_epochs,\n",
    "    testing_mode\n",
    "):\n",
    "    writer = SummaryWriter()  # create the TensorBoard object\n",
    "    # callback function to call during training, uses writer from the scope\n",
    "\n",
    "    def training_callback(epoch, lr, loss, validation_loss):\n",
    "        writer.add_scalars('data/autoencoder', {\n",
    "            'lr': lr,\n",
    "            'loss': loss,\n",
    "            'validation_loss': validation_loss,\n",
    "        }, epoch)\n",
    "    ds_train = CachedMNIST(train=True, cuda=cuda, testing_mode=testing_mode)  # training dataset\n",
    "    ds_val = CachedMNIST(train=False, cuda=cuda, testing_mode=testing_mode)  # evaluation dataset\n",
    "    autoencoder = StackedDenoisingAutoEncoder(\n",
    "        [28 * 28, 500, 500, 2000, 10],\n",
    "        final_activation=None\n",
    "    )\n",
    "    if cuda:\n",
    "        autoencoder.cuda()\n",
    "    print('Pretraining stage.')\n",
    "    ae.pretrain(\n",
    "        ds_train,\n",
    "        autoencoder,\n",
    "        cuda=cuda,\n",
    "        validation=ds_val,\n",
    "        epochs=pretrain_epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=lambda model: SGD(model.parameters(), lr=0.1, momentum=0.9),\n",
    "        scheduler=lambda x: StepLR(x, 100, gamma=0.1),\n",
    "        corruption=0.2\n",
    "    )\n",
    "    print('Training stage.')\n",
    "    ae_optimizer = SGD(params=autoencoder.parameters(), lr=0.1, momentum=0.9)\n",
    "    ae.train(\n",
    "        ds_train,\n",
    "        autoencoder,\n",
    "        cuda=cuda,\n",
    "        validation=ds_val,\n",
    "        epochs=finetune_epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=ae_optimizer,\n",
    "        scheduler=StepLR(ae_optimizer, 100, gamma=0.1),\n",
    "        corruption=0.2,\n",
    "        update_callback=training_callback\n",
    "    )\n",
    "    print('DEC stage.')\n",
    "    model = DEC(\n",
    "        cluster_number=10,\n",
    "        hidden_dimension=10,\n",
    "        encoder=autoencoder.encoder\n",
    "    )\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    dec_optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    train(\n",
    "        dataset=ds_train,\n",
    "        model=model,\n",
    "        epochs=100,\n",
    "        batch_size=256,\n",
    "        optimizer=dec_optimizer,\n",
    "        stopping_delta=0.000001,\n",
    "        cuda=cuda\n",
    "    )\n",
    "    predicted, actual = predict(ds_train, model, 1024, silent=True, return_actual=True, cuda=cuda)\n",
    "    actual = actual.cpu().numpy()\n",
    "    predicted = predicted.cpu().numpy()\n",
    "    reassignment, accuracy = cluster_accuracy(actual, predicted)\n",
    "    print('Final DEC accuracy: %s' % accuracy)\n",
    "    if not testing_mode:\n",
    "        predicted_reassigned = [reassignment[item] for item in predicted]  # TODO numpify\n",
    "        confusion = confusion_matrix(actual, predicted_reassigned)\n",
    "        normalised_confusion = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "        confusion_id = uuid.uuid4().hex\n",
    "        sns.heatmap(normalised_confusion).get_figure().savefig('confusion_%s.png' % confusion_id)\n",
    "        print('Writing out confusion diagram with UUID: %s' % confusion_id)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {\n",
    "    'cuda': 'True',\n",
    "    'batch_size':'',\n",
    "    'pretrain_epochs':'300',\n",
    "    'finetune_epochs':'500',\n",
    "    'testing_mode':'False'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(**params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
